{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TBEFN TF 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csxxqcaQBWv0"
      },
      "source": [
        "## TBEFN: A Two-branch Exposure-fusion Network for Low-light Image Enhancement\n",
        "TensorFlow 2.x implementation of this [paper](https://ieeexplore.ieee.org/document/9261119). No GPU runtime needed to execute the code in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QOLS2Z2-yzO"
      },
      "source": [
        "### Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USwFJ186CV3K"
      },
      "source": [
        "Clone the official repo just to use the provided pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EYgeJogCYu9"
      },
      "source": [
        "!git clone https://github.com/lukun199/TBEFN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfcyVW0wCiSg"
      },
      "source": [
        "%cd TBEFN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MLASFe4CcGt"
      },
      "source": [
        "Install **tf-slim**, as it isn't part anymore of the TensorFlow distribution since release 2.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB2Wk1YiG0ps"
      },
      "source": [
        "!pip install --upgrade tf_slim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W3iCktL_CeW"
      },
      "source": [
        "### Code preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmuc9Xn5_OXY"
      },
      "source": [
        "Create the input directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WKzSJBn_LMB"
      },
      "source": [
        "!mkdir ./input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNw8R3fK_Xfb"
      },
      "source": [
        "Import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4VLuVEi_qHI"
      },
      "source": [
        "import os, time\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import tf_slim as slim\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmJVX1Tr_COo"
      },
      "source": [
        "Set up the checkpoint, input and output directories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5uiQDjUANdE"
      },
      "source": [
        "checkpoint_dir = './ckpt/'\n",
        "input_dir = './input/'\n",
        "result_dir = './results/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uElAsSjqAPoN"
      },
      "source": [
        "Define the activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt5mQwNNAVXS"
      },
      "source": [
        "def out_acti(x):\n",
        "    return tf.nn.relu(x)-tf.nn.relu(x-1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtlKCOebAYZg"
      },
      "source": [
        "Define the denoising network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvXnSlIFDlJn"
      },
      "source": [
        "def denoise_net(input, name): # denoising, dense res linkage\n",
        "\n",
        "    with tf.variable_scope(name):\n",
        "\n",
        "        conv1_out = slim.conv2d(input, 3, [3, 3], rate=1, activation_fn=None, scope='di_conv1')\n",
        "\n",
        "        conv2_in = conv1_out\n",
        "        conv2_out = slim.conv2d(conv2_in, 3, [3, 3], rate=1, activation_fn=None, scope='di_conv2')\n",
        "\n",
        "        conv3_in = conv1_out + conv2_out\n",
        "        conv3_out = slim.conv2d(conv3_in, 3, [3, 3], rate=1, activation_fn=None, scope='di_conv3')\n",
        "\n",
        "        conv4_in = conv3_in + conv3_out\n",
        "        conv4_out = slim.conv2d(conv4_in, 3, [3, 3], rate=1, activation_fn=None, scope='di_conv4')\n",
        "\n",
        "        conv5_in = conv4_in + conv4_out\n",
        "        conv5_out = slim.conv2d(conv5_in, 3, [3, 3], rate=1, activation_fn=None, scope='di_conv5')\n",
        "\n",
        "        return out_acti(input + conv5_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WyfxAaWDqdK"
      },
      "source": [
        "Define the upsample and concatenation part of the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBrWQFvGDt3E"
      },
      "source": [
        "def upsample_and_concat(x1, x2, output_channels, in_channels):  \n",
        "    with tf.variable_scope(\"us_vars\"):\n",
        "        pool_size = 2\n",
        "        deconv_filter = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
        "        deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(x2), strides=[1, pool_size, pool_size, 1])\n",
        "\n",
        "        deconv_output = tf.concat([deconv, x2], 3)\n",
        "        deconv_output.set_shape([None, None, None, output_channels * 2])\n",
        "        return deconv_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-Z6fS6oEIoE"
      },
      "source": [
        "Define a simple U-Net."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHHSIhHhESms"
      },
      "source": [
        "def simple_unet(input,name): #input_1 forward ; input_2 details.\n",
        "\n",
        "    with tf.variable_scope(name):\n",
        "        conv_1 = slim.conv2d(input, 3, [3, 3], rate=1, activation_fn=None, scope='pp_conv1')\n",
        "        conv_2 = slim.conv2d(conv_1, 3, [3, 3], rate=1, activation_fn=None, scope='pp_conv2')\n",
        "        conv_3 = slim.conv2d(conv_2, 3, [3, 3], rate=1, activation_fn=tf.nn.relu,  scope='pp_conv3')\n",
        "        conv_4 = slim.conv2d(conv_3, 3, [3, 3], rate=1, activation_fn=tf.nn.relu, scope='pp_conv4')\n",
        "\n",
        "        #fusion\n",
        "        fu_1 = tf.concat([input, conv_4], 3)\n",
        "\n",
        "        conv1 = slim.conv2d(fu_1, 16, [3, 3], rate=1, activation_fn=tf.nn.relu,  scope='u_conv1')\n",
        "        pool1 = slim.max_pool2d(conv1, [2, 2], padding='SAME')\n",
        "        conv2 = slim.conv2d(pool1, 32, [3, 3], rate=1, activation_fn=tf.nn.relu,  scope='u_conv2')\n",
        "        pool2 = slim.max_pool2d(conv2, [2, 2], padding='SAME')\n",
        "        conv3 = slim.conv2d(pool2, 64, [3, 3], rate=1, activation_fn=tf.nn.relu, scope='u_conv3')\n",
        "        pool3 = slim.max_pool2d(conv3, [2, 2], padding='SAME')\n",
        "\n",
        "        conv4 = slim.conv2d(pool3, 128, [3, 3], rate=1, activation_fn=tf.nn.relu, scope='u_conv4')\n",
        "\n",
        "        up5 = upsample_and_concat(conv4, conv3, 64, 128)\n",
        "        conv5 = slim.conv2d(up5, 64, [3, 3], rate=1, activation_fn=tf.nn.relu, scope='u_conv5')\n",
        "\n",
        "        up6 = upsample_and_concat(conv5, conv2, 32, 64)\n",
        "        conv6 = slim.conv2d(up6, 32, [3, 3], rate=1, activation_fn=tf.nn.relu, scope='u_conv6')\n",
        "\n",
        "        up7 = upsample_and_concat(conv6, conv1, 16, 32)\n",
        "        conv7 = slim.conv2d(up7, 16, [3, 3], rate=1, activation_fn=tf.nn.relu, scope='u_conv7')\n",
        "\n",
        "        conv8 = slim.conv2d(conv7, 3, [3, 3], rate=1, activation_fn=tf.nn.relu, scope='u_conv8') # modified lk199\n",
        "\n",
        "        return conv8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJKZsD-HEfil"
      },
      "source": [
        "Define the fusion and attention."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmE9M95EEvOQ"
      },
      "source": [
        "def fusion(input_1,input_2,name):\n",
        "    with tf.variable_scope(name):\n",
        "        fusion_in = tf.concat([input_1, input_2], 3)\n",
        "        out_1 = slim.conv2d(fusion_in, 16, [3, 3], rate=1, activation_fn=tf.nn.relu, scope='fusion_1')\n",
        "        out_2 = slim.conv2d(out_1, 16, [3, 3], rate=1, activation_fn=tf.nn.relu, scope='fusion_2')\n",
        "        out_3 = slim.conv2d(out_2, 3, [3, 3], rate=1, activation_fn=None, scope='fusion_3')\n",
        "        return out_3\n",
        "\n",
        "def atten(input,name):\n",
        "    with tf.variable_scope(name):\n",
        "        out_1 = slim.conv2d(input, 16, [3, 3], rate=1, activation_fn=tf.nn.relu, scope='atten_1')\n",
        "        out_2 = slim.conv2d(out_1, 16, [3, 3], padding='SAME', rate=2, activation_fn=tf.nn.relu, scope='atten_2')\n",
        "        out_3 = slim.conv2d(out_2, 16, [3, 3], padding='SAME', rate=2, activation_fn=tf.nn.relu, scope='atten_3')\n",
        "        out_4 = slim.conv2d(out_3, 1, [3, 3], rate=1, activation_fn=None, scope='atten_4')\n",
        "        return out_acti(out_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9RH6OKEE2Tc"
      },
      "source": [
        "Define the model building function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OIZVm1-E1uu"
      },
      "source": [
        "def buildmodel(sample):\n",
        "\n",
        "    trans_fun_A_with_1E = simple_unet(sample, name='fun_est_A_with_1E')\n",
        "    enhanced_1E = out_acti(sample * trans_fun_A_with_1E)\n",
        "\n",
        "    denoised_in = denoise_net(sample, name='denoise_net')\n",
        "\n",
        "    trans_fun_B_with_2E = simple_unet(denoised_in, name='fun_est_B_with_2E')\n",
        "    enhanced_2E = out_acti(denoised_in * trans_fun_B_with_2E)\n",
        "\n",
        "    atten_map = atten(sample, name='atten')\n",
        "    fused = atten_map*enhanced_1E + (1-atten_map)*enhanced_2E\n",
        "\n",
        "    enhanced = fusion(fused, sample, name='fusion')\n",
        "\n",
        "    return enhanced"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MXrEMksGb31"
      },
      "source": [
        "### Blind low-light image enhancement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQOWj1P_Gft8"
      },
      "source": [
        "Define a function to upload images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5m5XtfxGo2J"
      },
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "def upload_files(upload_path):\n",
        "  uploaded = files.upload()\n",
        "  for filename, content in uploaded.items():\n",
        "    dst_path = os.path.join(upload_path, filename)\n",
        "    shutil.move(filename, dst_path)\n",
        "  return list(uploaded.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XUFTCcVKiYT"
      },
      "source": [
        "Upload your own images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN2VHGkvKlCh"
      },
      "source": [
        "uploaded_image_list = upload_files(input_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBXcHGpLKpDY"
      },
      "source": [
        "Display the updloaded images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANxSMJP-Kskg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_images(images_dir):\n",
        "  items = os.listdir(images_dir)\n",
        "  \n",
        "  for each_image in items:\n",
        "    if each_image.endswith(\".jpg\") or each_image.endswith(\".png\"):\n",
        "      print(each_image)\n",
        "      full_path = images_dir + '/' + each_image\n",
        "      image = cv2.imread(full_path)\n",
        "      image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "      plt.figure()\n",
        "      plt.imshow(image)\n",
        "      plt.grid(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWLzaMM0IyNJ"
      },
      "source": [
        "display_images(input_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hUSN0o2E6Yv"
      },
      "source": [
        "Finally build the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op8p8_LhFNB7"
      },
      "source": [
        "in_image = tf.placeholder(tf.float32, [None, None, None, 3])\n",
        "gt_image = tf.placeholder(tf.float32, [None, None, None, 3])  \n",
        "uf_out = buildmodel(in_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkK9XgZRL0qx"
      },
      "source": [
        "Display the model structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdJfOL9OL7o0"
      },
      "source": [
        "#print(uf_out.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdraY-kQFtL8"
      },
      "source": [
        "and perform low-light image enhancement on the uploaded images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5GLfytXFt50"
      },
      "source": [
        "sess = tf.compat.v1.Session()\n",
        "\n",
        "time_elapsed = 0\n",
        "with tf.Session() as sess:\n",
        "    saver = tf.compat.v1.train.Saver()\n",
        "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "    if ckpt:\n",
        "        print('loaded ' + ckpt.model_checkpoint_path)\n",
        "        saver.restore(sess, ckpt.model_checkpoint_path)  \n",
        "    \n",
        "    eval_fns = glob.glob(input_dir + '*.*')\n",
        "    for N in range(len(eval_fns)):\n",
        "        temp_train = np.array(cv2.imread(eval_fns[N]))  \n",
        "        temp_train = temp_train/255.0\n",
        "        train_data = temp_train.reshape(1, temp_train.shape[0], temp_train.shape[1], temp_train.shape[2])\n",
        "\n",
        "        st = time.time()\n",
        "        [out] = sess.run([uf_out], feed_dict={in_image: train_data})\n",
        "        time_elapsed += time.time() - st\n",
        "        print('%s' % eval_fns[N])\n",
        "\n",
        "        [_, name] = os.path.split(eval_fns[N])\n",
        "        suffix = name[name.find('.') + 1:]\n",
        "        name = name[:name.find('.')]\n",
        "\n",
        "        output = np.array(out[0])\n",
        "        output = output.reshape(output.shape[0], output.shape[1], output.shape[2])\n",
        "        output = output*255.0\n",
        "        output_rueslt = np.array(output)\n",
        "\n",
        "        if not os.path.isdir(result_dir):\n",
        "            os.makedirs(result_dir)\n",
        "        cv2.imwrite(result_dir + name + '_TBEFN.png', output_rueslt)\n",
        "\n",
        "    print('total processing time: ', time_elapsed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw4u2Ym8MYCY"
      },
      "source": [
        "Display the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjG2sWd5Mazq"
      },
      "source": [
        "display_images(result_dir)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}