{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV1bJqWLryNz"
      },
      "source": [
        "# Versatile Diffusion\n",
        "The [Versatile Diffusion](https://arxiv.org/abs/2211.08332) paper expands the existing single-flow diffusion pipeline into a multi-flow network that handles diverse generation tasks in one unified model. This notebook is to evaluate some of these tasks: text-to-image, image-variation and dual-guided generation. These tasks are executed here through the Hugging Face's [Diffusers](https://github.com/huggingface/diffusers) library.  \n",
        "![The Versatile Diffusion structure](https://github.com/SHI-Labs/Versatile-Diffusion/raw/master/assets/figures/vd_combined.png)  \n",
        "An hardware accelerated runtime (GPU) is required to execute the code in this notebook.  \n",
        "No need to execute the three tasks in this notebook in sequence: once the code cells in the *Settings* section have been successfully executed, you can then jump directly to the section(s) of interest.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp4WAONNWW3z"
      },
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUbrzoUsr7p8"
      },
      "source": [
        "Install any missing requirement in the Colab VM. Only *diffusers* (for PyTorch) and *transformers* need to be installed. Their installation will automaticall install also *huggingface-hub*, *accelerate* and *tokenizers*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8Lh31HPsDPU"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers[torch]\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxcQQPCoXmtW"
      },
      "source": [
        "Define a function to upload images to the Colab VM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptyyoIfsXqoG"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "def upload_files():\n",
        "  uploaded = files.upload()\n",
        "  for k, v in uploaded.items():\n",
        "    open(k, 'wb').write(v)\n",
        "  return list(uploaded.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jOZUNKQVltN"
      },
      "source": [
        "Import the general dependencies across multiple tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2HjAcZwVr8b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di-Ib-isX6mj"
      },
      "source": [
        "## Text to Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1moW9pEaA5r"
      },
      "source": [
        "Create the Versatile Diffusion pipeline for this task. For all the pipelines in this notebook, the float 16 version of the pre-trained models are used, as their size is half of the the same for the float 32 models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnXhXGdsaBcX"
      },
      "outputs": [],
      "source": [
        "from diffusers import VersatileDiffusionTextToImagePipeline\n",
        "\n",
        "pipe = VersatileDiffusionTextToImagePipeline.from_pretrained(\"shi-labs/versatile-diffusion\", torch_dtype=torch.float16)\n",
        "pipe.remove_unused_weights()\n",
        "pipe = pipe.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Mhv07nzfDz"
      },
      "source": [
        "Setup prompt, seed and strength to perform a text to image task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECA_ll0BYFpe"
      },
      "outputs": [],
      "source": [
        "text2img_prompt = \"Sticker of a cute spider, white border, die cut, head, cute, trending on artstation\" #@param {type: \"string\"}\n",
        "text2img_seed = 0 #@param {type: \"number\"}\n",
        "text2img_strength = 0.75 #@param {type:\"slider\", min:0, max:1, step:0.05}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scb2CvHPaSvd"
      },
      "source": [
        "Do text to image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2-2_XqJzhYA"
      },
      "outputs": [],
      "source": [
        "generator = torch.Generator(device=\"cuda\").manual_seed(text2img_seed)\n",
        "image = pipe(text2img_prompt, \n",
        "             generator=generator,\n",
        "             strength=text2img_strength).images[0]\n",
        "display(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSd65C8e0uSl"
      },
      "source": [
        "## Image Variation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MfqXZbUaROh"
      },
      "source": [
        "Create the Versatile Diffusion pipeline for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm9NqQTVaScN"
      },
      "outputs": [],
      "source": [
        "from diffusers import VersatileDiffusionImageVariationPipeline\n",
        "\n",
        "pipe = VersatileDiffusionImageVariationPipeline.from_pretrained(\"shi-labs/versatile-diffusion\", torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UHsBnEnayUr"
      },
      "source": [
        "Upload source image(s)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8ejo_9Ya43E"
      },
      "outputs": [],
      "source": [
        "uploaded_image_variation_list = upload_files()\n",
        "uploaded_image_variation_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_XePNHMaoeF"
      },
      "source": [
        "Select a source image and set seed and strength. Because the Colab forms dropdown doesn't support variables, the only way to specify the source image filename is to copy and paste it from the previous code cell output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5G1VnUfaEFC"
      },
      "outputs": [],
      "source": [
        "image_variation_source = \"pexels-pixabay-48785.jpg\" #@param {type: \"string\"}\n",
        "image_variation_seed = 222222 #@param {type: \"number\"}\n",
        "image_variation_strength = 0.75 #@param {type:\"slider\", min:0, max:1, step:0.05}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9DvN4iApohl"
      },
      "source": [
        "Do image variation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMESviAh0xCn"
      },
      "outputs": [],
      "source": [
        "image = Image.open(image_variation_source)\n",
        "display(image)\n",
        "\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(image_variation_seed)\n",
        "image = pipe(image, \n",
        "             generator=generator,\n",
        "             strength=image_variation_strength).images[0]\n",
        "display(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m2TMJras8rT"
      },
      "source": [
        "## Dual-guided Generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9i-W9T6yLSD"
      },
      "source": [
        "Create the Versatile Diffusion pipeline for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSJ4MrcU1D3R"
      },
      "outputs": [],
      "source": [
        "from diffusers import VersatileDiffusionDualGuidedPipeline\n",
        "\n",
        "pipe = VersatileDiffusionDualGuidedPipeline.from_pretrained(\"shi-labs/versatile-diffusion\", torch_dtype=torch.float16)\n",
        "pipe.remove_unused_weights()\n",
        "pipe = pipe.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK7fkai_hjaG"
      },
      "source": [
        "Upload some image(s)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2ImYIBYvQHy"
      },
      "outputs": [],
      "source": [
        "uploaded_dual_guided_list = upload_files()\n",
        "uploaded_dual_guided_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX1cxxLKgJbX"
      },
      "source": [
        "Select the source image and set the prompt, the seed and the strength value. Again, the only way to specify the source image filename is to copy and paste it from the previous code cell output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdMafLA4so1f"
      },
      "outputs": [],
      "source": [
        "dual_guided_source = \"marvel-spiderman-i15585.jpg\" #@param {type: \"string\"}\n",
        "dual_guided_prompt = \"Spider man. blade runner 2049 concept painting.  painting with vivid color.\" #@param {type: \"string\"}\n",
        "dual_guided_seed = 555557 #@param {type: \"number\"}\n",
        "dual_guided_strength = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.05}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91tkpCmX1KEK"
      },
      "source": [
        "Do dual-guided generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1nIHppbx_yg"
      },
      "outputs": [],
      "source": [
        "image = Image.open(dual_guided_source)\n",
        "display(image)\n",
        "\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(dual_guided_seed)\n",
        "\n",
        "image = pipe(prompt=dual_guided_prompt, \n",
        "             image=image, \n",
        "             text_to_image_strength=dual_guided_strength, \n",
        "             generator=generator).images[0]\n",
        "display(image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
